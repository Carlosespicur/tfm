{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17413,"status":"ok","timestamp":1714819441302,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"xwqZV78OMxvV","outputId":"87487b09-bcac-455c-e6f5-4ce49f7483dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch_scatter\\_scatter_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch_geometric\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torch_geometric.utils import dense_to_sparse\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from torch.optim import Adam\n","from matplotlib import pyplot as plt\n","import json\n","import os"]},{"cell_type":"markdown","metadata":{"id":"-gt7UsxOMxvX"},"source":[" Similarity metrics"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# PyTorch implementations of Polynomial Kernels\n","\n","def polynomial_kernel(X, Y, degree=2, gamma=1.0, coef0=1.0):\n","    \"\"\"\n","    Polynomial kernel function.\n","    :param X: torch.Tensor of shape (n_samples_1, n_features)\n","    :param Y: torch.Tensor of shape (n_samples_2, n_features)\n","    :param degree: int, default=2\n","    :param gamma: float, default=1.0\n","    :param coef0: float, default=1.0\n","    :return: torch.Tensor of shape (n_samples_1, n_samples_2)\n","    \"\"\"\n","    K = (gamma * torch.mm(X, Y.t()) + coef0) ** degree\n","    return K\n","\n","def rbf_kernel(X, Y, gamma=None):\n","\n","    \"\"\"\n","    Rbf kernel function.\n","    :param X: torch.Tensor of shape (n_samples_1, n_features)\n","    :param Y: torch.Tensor of shape (n_samples_2, n_features)\n","    :param gamma: float or None, default=None\n","    :return: torch.Tensor of shape (n_samples_1, n_samples_2)\n","    \"\"\"\n","\n","    if gamma == None:\n","        gamma = 1.0/X.size(1) # gamma = 1/n_features\n","    \n","    # K(x, y) = exp(-gamma ||x-y||^2)\n","    d_XY = torch.cdist(X, Y, p=2) # pairwise distances between X and Y rows. Shape = (n_samples_1, n_samples_2)\n","    K = torch.exp(-gamma * d_XY ** 2)\n","\n","    return K\n","\n","def laplacian_kernel(X, Y, gamma=None):\n","    \"\"\"\n","    Laplacian kernel function.\n","    :param X: torch.Tensor of shape (n_samples_1, n_features)\n","    :param Y: torch.Tensor of shape (n_samples_2, n_features)\n","    :param gamma: float or None, default=None\n","    :return: torch.Tensor of shape (n_samples_1, n_samples_2)\n","    \"\"\"\n","\n","    if gamma == None:\n","        gamma = 1.0/X.size(1) # gamma = 1/n_features\n","    \n","    # K(x, y) = exp(-gamma ||x-y||)\n","    d_XY = torch.cdist(X, Y, p=1) # pairwise distances between X and Y rows. Shape = (n_samples_1, n_samples_2)\n","    K = torch.exp(-gamma * d_XY)\n","\n","    return K\n","\n","def sigmoid_kernel(X, Y, gamma=1.0, coef0=1.0):\n","    \"\"\"\n","    Sigmoid kernel function.\n","    :param X: torch.Tensor of shape (n_samples_1, n_features)\n","    :param Y: torch.Tensor of shape (n_samples_2, n_features)\n","    :param gamma: float, default=1.0\n","    :param coef0: float, default=1.0\n","    :return: torch.Tensor of shape (n_samples_1, n_samples_2)\n","    \"\"\"\n","    K = torch.tanh(gamma * torch.mm(X, Y.t()) + coef0)\n","    return K\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1714819446087,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"5TVkU_A1MxvY"},"outputs":[],"source":["def binary_distance(X, Y):\n","    \"\"\"Compute distance matrix between  rows of X, Y.\n","\n","    d(x_i, y_j) = 1 if x_i == y_j, 0 in other case.\n","\n","    for all rows x_i in X, y_j in Y\n","\n","    \"\"\"\n","    return (X.unsqueeze(1) == Y.unsqueeze(0)).all(-1).float()\n","\n","\n","def kernel(X, *args, **kwargs):\n","    \"\"\"\n","    Compute similarity matrix of an array X using a variety of kernels\n","    Parameters:\n","        X = input data (torch.Tensor or numpy array)\n","    \"\"\"\n","    # kernel parameters\n","\n","    degree = kwargs.get(\"degree\", None)\n","    gamma = kwargs.get(\"gamma\", None)\n","    coef = kwargs.get(\"coef\", None)\n","    kernel_type = kwargs.get(\"kernel_type\", None)\n","\n","    if kernel_type == \"polynomial\":\n","\n","\n","        # K(x,y) = (gamma * <x,y> + coef)^degree, for vectors x,y\n","\n","        if (gamma != None) & (coef != None) & (degree != None):\n","            return polynomial_kernel(X = X, Y = X, degree = degree, gamma = gamma, coef0 = coef)\n","        else:\n","            return None\n","\n","    elif kernel_type == \"sigmoid\":\n"," \n","        # K(x,y) = tanh(gamma * <x,y> + coef), for vectors x,y\n","\n","        if (gamma != None) & (coef != None):\n","            return sigmoid_kernel(X = X, Y = X, gamma = gamma, coef0 = coef)\n","        else:\n","            return None\n","\n","    elif kernel_type == \"rbf\":\n","\n","        # K(x, y) = exp(-gamma ||x-y||^2)\n","\n","        if (gamma != None):\n","            return rbf_kernel(X = X, Y = X, gamma = gamma)\n","        else:\n","            return None\n","\n","    elif kernel_type == \"laplacian\":\n","\n","        # K(x, y) = exp(-gamma ||x-y||_1)\n","\n","        if (gamma != None):\n","            return laplacian_kernel(X = X, Y = X, gamma = gamma)\n","        else:\n","            return None\n","\n","    else:\n","        return None\n"]},{"cell_type":"markdown","metadata":{"id":"0zJ1RjIKMxvZ"},"source":["Model definition"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1714819450132,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"vYF-HdHgMxvZ"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, latent_size):\n","        super().__init__()\n","        self.layer1 = GCNConv(input_size, latent_size)\n","        \n","        self.activation = nn.LeakyReLU()\n","    def forward(self, x):\n","        x = self.activation(self.layer1(x))\n","        return x\n","\n","class Encoder_graph_triplet_loss(nn.Module):\n","    def __init__(self, encoder, kernel_parameters_X, optimizer, label_indep = False, kernel_parameters_Y = None, gamma = 0.1):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.kernel_parameters_X = kernel_parameters_X\n","        self.optimizer = optimizer\n","        self.label_indep = label_indep\n","        self.kernel_parameters_Y = kernel_parameters_Y\n","        self.gamma = gamma\n","    \n","    def encode(self, x):\n","        return self.encoder(x)\n","    \n","    def train_model(self, data_loader):\n","        self.train()\n","        \n","        epoch_losses = []\n","\n","        for X, y in tqdm(data_loader):\n","            self.optimizer.zero_grad()\n","            Z = self.encode(X)\n","\n","            # Calculation of similarity matrices\n","\n","            K_Z = kernel(Z, **self.kernel_parameters_X)\n","            K_X = kernel(X, **self.kernel_parameters_X)\n","            d_Z = torch.cdist(Z, Z, p=2)\n","            if self.label_indep: # data with different labels has not relationship (e.g: multiclass classification)\n","                K_Y = binary_distance(y.unsqueeze(1), y.unsqueeze(1))\n","            else:\n","                if self.kernel_parameters_Y == None:\n","                    self.kernel_parameters_Y = self.kernel_parameters_X\n","                K_Y = kernel(y, **self.kernel_parameters_Y)\n","            \n","            loss = torch.sum(K_X * K_Y * d_Z)\n","            epoch_losses.append(loss)\n","\n","            loss.backward()\n","            self.optimizer.step()\n","        \n","        avg_loss = torch.mean(torch.Tensor(epoch_losses))\n","        return avg_loss.item()\n","    \n","    def test_model(self, data_loader):\n","        self.eval()\n","        epoch_losses = []\n","\n","        with torch.no_grad():\n","            for X, y in data_loader:\n","                Z = self.encode(X)\n","\n","                # Calculation of similarity matrices\n","\n","                K_Z = kernel(Z, **self.kernel_parameters_X)\n","                K_X = kernel(X, **self.kernel_parameters_X)\n","                d_Z = torch.cdist(Z, Z, p=2)\n","                if self.label_indep: # data with different labels has not relationship (e.g: multiclass classification)\n","                    K_Y = binary_distance(y.unsqueeze(1), y.unsqueeze(1))\n","                else:\n","                    if self.kernel_parameters_Y == None:\n","                        self.kernel_parameters_Y = self.kernel_parameters_X\n","                    K_Y = kernel(y, **self.kernel_parameters_Y)\n","            \n","                loss = torch.sum(K_X * K_Y * d_Z)\n","                epoch_losses.append(loss)\n","            \n","        avg_loss = torch.mean(torch.Tensor(epoch_losses))\n","        return avg_loss.item()\n","            \n","            \n","\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"ufn5xrinMxvZ"},"source":["Model hyperparameters"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1714819643983,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"TuXX2kmNMxvZ"},"outputs":[],"source":["lr = 0.001 # learning rate\n","batch_size = 64\n","epochs = 1000\n","latent_size = 64 # latent space dimension\n","\n","kernel_param_X = {\n","\n","    \"kernel_type\": \"rbf\",\n","    \"degree\": 3,\n","    \"gamma\": 1e-2,\n","    \"coef\": 0.5e2\n","\n","}\n","\n","# kernel function parameters for Y_train / Y_test. If is equal to None, we use the same parameters.\n","\n","kernel_param_Y = None\n","\n","\"\"\"\n","kernel_param_Y = {\n","\n","    \"kernel_type\": \"polynomial\",\n","    \"degree\": 3,\n","    \"gamma\": 1.,\n","    \"coef\": 1.\n","\n","}\n","\"\"\"\n","\n","label_indep = True # True for categoric labels, False for numerical labels"]},{"cell_type":"markdown","metadata":{"id":"OysDy5zvMxva"},"source":["MNIST Fashion preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13226,"status":"ok","timestamp":1714819517694,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"-oK6nmVxNQtT","outputId":"509b45b8-ff3a-4c4c-887c-1feaf4dfb836"},"outputs":[],"source":["# !git clone \"https://github.com/Carlosespicur/tfm_esteban\""]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7104,"status":"ok","timestamp":1714819583658,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"k-mTK64oMxva"},"outputs":[],"source":["\n","\n","# train_data = pd.read_csv(\"/content/tfm_esteban/fashion_MNIST/fashion-mnist_train.csv\")\n","# test_data = pd.read_csv(\"/content/tfm_esteban/fashion_MNIST/fashion-mnist_test.csv\")\n","\n","train_data = pd.read_csv(\"fashion_MNIST/fashion-mnist_train.csv\")\n","test_data = pd.read_csv(\"fashion_MNIST/fashion-mnist_test.csv\")\n","data = pd.concat([train_data, test_data], ignore_index = True)\n","# print(train_data.shape, test_data.shape, data.shape)\n","# data.head()\n","train_data, test_data = train_test_split(data, test_size=0.2, shuffle=True, stratify=data[\"label\"], random_state=20)\n","train_data, val_data = train_test_split(train_data, test_size=0.1, shuffle=True, stratify=train_data[\"label\"], random_state=20)\n","\n","# print(train_data[\"label\"].value_counts(normalize=True))\n","# print(val_data[\"label\"].value_counts(normalize=True))\n","# print(test_data[\"label\"].value_counts(normalize=True))\n","\n","X_train = np.array(train_data.drop(\"label\", axis = 1, inplace=False))/255\n","X_train = torch.tensor(X_train, dtype = torch.float)\n","y_train = train_data[\"label\"].values\n","y_train = torch.tensor(y_train, dtype = torch.float)\n","X_val = np.array(val_data.drop(\"label\", axis = 1, inplace=False))/255\n","X_val = torch.tensor(X_val, dtype = torch.float)\n","y_val = val_data[\"label\"].values\n","y_val = torch.tensor(y_val, dtype = torch.float)\n","X_test = np.array(test_data.drop(\"label\", axis = 1, inplace=False))/255\n","X_test = torch.tensor(X_test, dtype = torch.float)\n","y_test = test_data[\"label\"].values\n","y_test = torch.tensor(y_test, dtype = torch.float)\n","\n","train_loader = DataLoader(list(zip(X_train, y_train)), shuffle = True, batch_size=batch_size)\n","val_loader = DataLoader(list(zip(X_val, y_val)), shuffle = True, batch_size=batch_size)\n","test_loader = DataLoader(list(zip(X_test, y_test)), shuffle = False, batch_size=batch_size)\n","\n","input_size = X_train.size(1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # PRUEBA CON DATASET ORIGINAL \n","\n","# # train_data = pd.read_csv(\"/content/tfm_esteban/fashion_MNIST/fashion-mnist_train.csv\")\n","# # test_data = pd.read_csv(\"/content/tfm_esteban/fashion_MNIST/fashion-mnist_test.csv\")\n","\n","# train_data = pd.read_csv(\"../datasets/fashion_MNIST/fashion-mnist_train.csv\")\n","# test_data = pd.read_csv(\"../datasets/fashion_MNIST/fashion-mnist_test.csv\")\n","# # data = pd.concat([train_data, test_data], ignore_index = True)\n","# # print(train_data.shape, test_data.shape, data.shape)\n","# # data.head()\n","# # train_data, test_data = train_test_split(data, test_size=0.2, shuffle=True, stratify=data[\"label\"], random_state=20)\n","# train_data, val_data = train_test_split(train_data, test_size=0.1, shuffle=True, stratify=train_data[\"label\"], random_state=20)\n","\n","# # print(train_data[\"label\"].value_counts(normalize=True))\n","# # print(val_data[\"label\"].value_counts(normalize=True))\n","# # print(test_data[\"label\"].value_counts(normalize=True))\n","\n","# X_train = np.array(train_data.drop(\"label\", axis = 1, inplace=False))/255\n","# X_train = torch.tensor(X_train, dtype = torch.float)\n","# y_train = train_data[\"label\"].values\n","# y_train = torch.tensor(y_train, dtype = torch.float)\n","# X_val = np.array(val_data.drop(\"label\", axis = 1, inplace=False))/255\n","# X_val = torch.tensor(X_val, dtype = torch.float)\n","# y_val = val_data[\"label\"].values\n","# y_val = torch.tensor(y_val, dtype = torch.float)\n","# X_test = np.array(test_data.drop(\"label\", axis = 1, inplace=False))/255\n","# X_test = torch.tensor(X_test, dtype = torch.float)\n","# y_test = test_data[\"label\"].values\n","# y_test = torch.tensor(y_test, dtype = torch.float)\n","\n","# train_loader = DataLoader(list(zip(X_train, y_train)), shuffle = True, batch_size=batch_size)\n","# val_loader = DataLoader(list(zip(X_val, y_val)), shuffle = True, batch_size=batch_size)\n","# test_loader = DataLoader(list(zip(X_test, y_test)), shuffle = False, batch_size=batch_size)\n","\n","# input_size = X_train.size(1)"]},{"cell_type":"markdown","metadata":{"id":"5pGBYbqbMxva"},"source":["Model creation"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1714819649550,"user":{"displayName":"CARLOS ESPINOZA CURTO","userId":"10212750325364301040"},"user_tz":-120},"id":"OQsCv2EvMxva"},"outputs":[],"source":["encoder = Encoder(input_size, latent_size)\n","optimizer = Adam(list(encoder.parameters()), lr = lr)\n","\n","model = Encoder_graph_triplet_loss(encoder, kernel_param_X, optimizer, label_indep, kernel_param_Y, gamma = 0.2)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"e56bKkTsMxvb"},"source":["Model training"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOfUedO8Mxvb","outputId":"b02a3453-6bb3-4841-c572-313bcd016921"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.341322660446167\n","avg_loss_val: 0.026273531839251518\n","Epoch: 2/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 39.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.015629012137651443\n","avg_loss_val: 0.05184765160083771\n","Epoch: 3/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.011789729818701744\n","avg_loss_val: 0.0071005914360284805\n","Epoch: 4/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.008824305608868599\n","avg_loss_val: 0.0016518216580152512\n","Epoch: 5/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0061372313648462296\n","avg_loss_val: 0.005133293569087982\n","Epoch: 6/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0094786137342453\n","avg_loss_val: 0.0051240697503089905\n","Epoch: 7/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.005819648504257202\n","avg_loss_val: 0.006587706971913576\n","Epoch: 8/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.005568081978708506\n","avg_loss_val: 0.003907488659024239\n","Epoch: 9/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.004440057557076216\n","avg_loss_val: 0.003238046308979392\n","Epoch: 10/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0034471601247787476\n","avg_loss_val: 0.00370758306235075\n","Epoch: 11/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 39.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0031158174388110638\n","avg_loss_val: 0.0038517480716109276\n","Epoch: 12/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0008865422569215298\n","avg_loss_val: 0.0001803260820452124\n","Epoch: 13/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00017460207163821906\n","avg_loss_val: 0.00017368001863360405\n","Epoch: 14/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 40.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.061942968517541885\n","avg_loss_val: 0.06279008835554123\n","Epoch: 15/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.007761178072541952\n","avg_loss_val: 0.0033460960257798433\n","Epoch: 16/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 39.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.002882987493649125\n","avg_loss_val: 0.0019799498841166496\n","Epoch: 17/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.002332074800506234\n","avg_loss_val: 0.002027178416028619\n","Epoch: 18/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0019730140920728445\n","avg_loss_val: 0.0028047028463333845\n","Epoch: 19/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.001595434034243226\n","avg_loss_val: 0.002944067120552063\n","Epoch: 20/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0012223623925819993\n","avg_loss_val: 0.0016779855359345675\n","Epoch: 21/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 38.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0008968512993305922\n","avg_loss_val: 0.0007694898522458971\n","Epoch: 22/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0006937091238796711\n","avg_loss_val: 0.0010666761081665754\n","Epoch: 23/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 39.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0005396859487518668\n","avg_loss_val: 0.00035279744770377874\n","Epoch: 24/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0005071956547908485\n","avg_loss_val: 0.0008692029514349997\n","Epoch: 25/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 39.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00043254808406345546\n","avg_loss_val: 0.00032178210676647723\n","Epoch: 26/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00039178307633847\n","avg_loss_val: 0.0005113693769089878\n","Epoch: 27/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:20<00:00, 39.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.0003947773657273501\n","avg_loss_val: 0.0003191088035237044\n","Epoch: 28/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00031752820359542966\n","avg_loss_val: 0.00033024733420461416\n","Epoch: 29/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00035542011028155684\n","avg_loss_val: 0.0003007765335496515\n","Epoch: 30/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 39.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00031697022495791316\n","avg_loss_val: 0.00045104234595783055\n","Epoch: 31/1000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:19<00:00, 40.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 0.00030646685627289116\n","avg_loss_val: 0.0002841884270310402\n","Epoch: 32/1000\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 163/788 [00:04<00:15, 39.60it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     avg_loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     avg_loss_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtest_model(val_loader)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_loss_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[21], line 52\u001b[0m, in \u001b[0;36mEncoder_graph_triplet_loss.train_model\u001b[1;34m(self, data_loader)\u001b[0m\n\u001b[0;32m     49\u001b[0m     epoch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     51\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mTensor(epoch_losses))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    303\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    307\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(epochs):\n","    print(f\"Epoch: {epoch + 1}/{epochs}\")\n","    avg_loss_train = model.train_model(train_loader)\n","    avg_loss_val = model.test_model(val_loader)\n","\n","    print(f\"avg_loss_train: {avg_loss_train}\")\n","    print(f\"avg_loss_val: {avg_loss_val}\")\n"]},{"cell_type":"markdown","metadata":{"id":"v3Wv6ljKMxvb"},"source":["Model testing"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"by5YRcnCMxvb","outputId":"d76e7ef2-d6b3-41de-f778-567c74d29807"},"outputs":[{"data":{"text/plain":["0.00028642782126553357"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model.test_model(test_loader)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"p7-2EIlSMxvc"},"outputs":[],"source":["for X, y in test_loader:\n","    Z = model.encode(X)\n","    break"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"BE1vOx9SMxvc","outputId":"df6a093e-70fb-4bf3-f7f9-368b79924ce1"},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x1f53b33adc0>"]},"execution_count":37,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["data_number = 13\n","prueba = X[data_number].detach().numpy().reshape(28, 28)\n","plt.imshow(prueba, cmap = \"gray\")"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(8.)\n","tensor([-0.0006, -0.0010, -0.0006, -0.0006, -0.0005, -0.0008, -0.0009, -0.0009,\n","        -0.0006, -0.0006, -0.0004, -0.0008, -0.0005, -0.0007, -0.0006, -0.0005,\n","        -0.0006, -0.0007, -0.0008, -0.0003, -0.0007, -0.0007, -0.0006, -0.0008,\n","        -0.0007, -0.0004, -0.0010, -0.0006, -0.0010, -0.0006, -0.0006, -0.0004,\n","        -0.0010, -0.0006, -0.0008, -0.0002, -0.0006, -0.0007, -0.0008, -0.0010,\n","        -0.0006, -0.0010, -0.0009, -0.0006, -0.0003, -0.0008, -0.0008, -0.0013,\n","        -0.0008, -0.0008, -0.0005, -0.0006, -0.0006, -0.0010, -0.0007, -0.0008,\n","        -0.0005, -0.0007, -0.0003, -0.0004, -0.0004, -0.0010, -0.0005, -0.0007],\n","       grad_fn=<SelectBackward0>)\n"]}],"source":["print(y[data_number])\n","\n","print(Z[data_number])"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n","        [0., 1., 0.,  ..., 1., 0., 0.],\n","        [0., 0., 1.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 1., 0.,  ..., 1., 0., 0.],\n","        [1., 0., 0.,  ..., 0., 1., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 1.]], grad_fn=<MulBackward0>)\n","tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3559, 0.0000],\n","        [0.0000, 1.0000, 0.0000,  ..., 0.3317, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.3317, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n","        [0.3559, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])\n"]}],"source":["K_Z = kernel(Z, **kernel_param_X)\n","K_X = kernel(X, **kernel_param_X)\n","K_Y = binary_distance(y.unsqueeze(1), y.unsqueeze(1))\n","\n","print(K_Z * K_Y)\n","print(K_X * K_Y)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"Gc3q0ClQMxvc","outputId":"81e2bd4b-df3d-4e94-d045-ca7731f9745f"},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x1f53b3fff40>"]},"execution_count":39,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["prueba_out = Z[data_number].detach().numpy().reshape(8, 8)\n","plt.imshow(prueba_out, cmap = \"gray\")"]},{"cell_type":"markdown","metadata":{},"source":["Training a MLP for classification with embeddings of the previous GNN model"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["class MLP(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_hidden_layers, output_size, lr, criterion, use_embeddings = True):\n","    super().__init__()\n","    \n","    self.criterion = criterion\n","    activation = nn.ReLU()\n","    self.MLP_layers = nn.ModuleList()\n","    layer = nn.Linear(input_size, hidden_size)\n","    nn.init.xavier_uniform(layer.weight)\n","    layer.bias.data.fill_(0.01)\n","    self.MLP_layers.append(layer)\n","    self.MLP_layers.append(activation)\n","    self.use_embeddings = use_embeddings\n","\n","    for _ in range(num_hidden_layers - 1):\n","\n","      layer = nn.Linear(hidden_size, hidden_size)\n","      nn.init.xavier_uniform(layer.weight)\n","      layer.bias.data.fill_(0.01)\n","      self.MLP_layers.append(layer)\n","      self.MLP_layers.append(activation)\n","\n","    layer = nn.Linear(hidden_size, output_size)\n","    nn.init.xavier_uniform(layer.weight)\n","    layer.bias.data.fill_(0.01)\n","    self.MLP_layers.append(layer)\n","    self.MLP_layers.append(nn.Sigmoid())\n","\n","    self.optimizer = Adam(self.parameters(), lr)\n","\n","  def forward(self, x):\n","    for layer in self.MLP_layers:\n","      x = layer(x)\n","\n","    return x\n","  \n","  def train_model(self, train_loader):\n","\n","    self.train()\n","\n","    epoch_losses = []\n","    epoch_accuracies = []\n","\n","    for X, y in tqdm(train_loader):\n","\n","      self.optimizer.zero_grad()\n","      if self.use_embeddings:\n","        with torch.no_grad():\n","          Z = model.encode(X)\n","        out = self.forward(Z)\n","      else:\n","        out = self.forward(X)\n","      \n","      loss = self.criterion(out, y.long())\n","      preds = torch.argmax(out, dim = 1)\n","      accuracy = torch.mean((preds == y.long()).float())\n","      epoch_losses.append(loss)\n","      epoch_accuracies.append(accuracy)\n","      loss.backward()\n","      self.optimizer.step()\n","\n","    avg_loss = torch.mean(torch.Tensor(epoch_losses))\n","    avg_accuracy = torch.mean(torch.Tensor(epoch_accuracies))\n","\n","    return avg_loss.item(), avg_accuracy.item()\n","  \n","  def test_model(self, data_loader):\n","\n","    self.eval()\n","\n","    test_losses = []\n","    test_accuracies = []\n","\n","    for X, y in tqdm(data_loader):\n","        if self.use_embeddings:\n","          with torch.no_grad():\n","            Z = model.encode(X)\n","          out = self.forward(Z)\n","        else:\n","          out = self.forward(X)\n","        \n","        loss = self.criterion(out, y.long())\n","        preds = torch.argmax(out, dim = 1)\n","        accuracy = torch.mean((preds == y.long()).float())\n","        test_losses.append(loss)\n","        test_accuracies.append(accuracy)\n","    avg_loss = torch.mean(torch.Tensor(test_losses))\n","    avg_accuracy = torch.mean(torch.Tensor(test_accuracies))\n","\n","    return avg_loss.item(), avg_accuracy.item()\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Carlos\\AppData\\Local\\Temp\\ipykernel_2244\\3759001460.py:9: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  nn.init.xavier_uniform(layer.weight)\n","C:\\Users\\Carlos\\AppData\\Local\\Temp\\ipykernel_2244\\3759001460.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  nn.init.xavier_uniform(layer.weight)\n","C:\\Users\\Carlos\\AppData\\Local\\Temp\\ipykernel_2244\\3759001460.py:24: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  nn.init.xavier_uniform(layer.weight)\n"]}],"source":["lr_classif = 0.001\n","loss = nn.CrossEntropyLoss()\n","classif = MLP(latent_size, 16, 3, 10, lr_classif, loss, use_embeddings = True)"]},{"cell_type":"code","execution_count":201,"metadata":{},"outputs":[{"data":{"text/plain":["<bound method Module.parameters of MLP(\n","  (criterion): CrossEntropyLoss()\n","  (MLP_layers): ModuleList(\n","    (0): Linear(in_features=64, out_features=16, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=16, out_features=16, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=16, out_features=16, bias=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=16, out_features=10, bias=True)\n","    (7): Sigmoid()\n","  )\n",")>"]},"execution_count":201,"metadata":{},"output_type":"execute_result"}],"source":["classif.parameters"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["epochs_classif = 200"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 1/200\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:11<00:00, 70.49it/s]\n","100%|██████████| 88/88 [00:01<00:00, 82.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 2.3026, avg_accuracy_train: 0.0962\n","avg_loss_val: 2.3026, avg_accuracy_val: 0.0998\n","epoch: 2/200\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:11<00:00, 70.99it/s]\n","100%|██████████| 88/88 [00:01<00:00, 82.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 2.3026, avg_accuracy_train: 0.0996\n","avg_loss_val: 2.3026, avg_accuracy_val: 0.1000\n","epoch: 3/200\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:11<00:00, 69.99it/s]\n","100%|██████████| 88/88 [00:01<00:00, 82.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 2.3026, avg_accuracy_train: 0.0968\n","avg_loss_val: 2.3026, avg_accuracy_val: 0.1003\n","epoch: 4/200\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:11<00:00, 70.52it/s]\n","100%|██████████| 88/88 [00:01<00:00, 82.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 2.3026, avg_accuracy_train: 0.0967\n","avg_loss_val: 2.3026, avg_accuracy_val: 0.0996\n","epoch: 5/200\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:11<00:00, 70.96it/s]\n","100%|██████████| 88/88 [00:01<00:00, 82.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 2.3026, avg_accuracy_train: 0.0983\n","avg_loss_val: 2.3026, avg_accuracy_val: 0.0996\n","epoch: 6/200\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [00:11<00:00, 70.28it/s]\n","100%|██████████| 88/88 [00:01<00:00, 80.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["avg_loss_train: 2.3026, avg_accuracy_train: 0.0973\n","avg_loss_val: 2.3026, avg_accuracy_val: 0.0994\n","epoch: 7/200\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 175/788 [00:02<00:09, 67.07it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs_classif):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs_classif\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     avg_loss_train, avg_accuracy_train \u001b[38;5;241m=\u001b[39m \u001b[43mclassif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# validation data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     avg_loss_val, avg_accuracy_val \u001b[38;5;241m=\u001b[39m classif\u001b[38;5;241m.\u001b[39mtest_model(val_loader)\n","Cell \u001b[1;32mIn[30], line 49\u001b[0m, in \u001b[0;36mMLP.train_model\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_embeddings:\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 49\u001b[0m     Z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(Z)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","Cell \u001b[1;32mIn[21], line 25\u001b[0m, in \u001b[0;36mEncoder_graph_triplet_loss.encode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[21], line 9\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# MLP training\n","for epoch in range(epochs_classif):\n","    print(f\"epoch: {epoch + 1}/{epochs_classif}\")\n","    avg_loss_train, avg_accuracy_train = classif.train_model(train_loader)\n","\n","    # validation data\n","    avg_loss_val, avg_accuracy_val = classif.test_model(val_loader)\n","\n","    print(f\"avg_loss_train: {avg_loss_train:.4f}, avg_accuracy_train: {avg_accuracy_train:.4f}\")\n","    print(f\"avg_loss_val: {avg_loss_val:.4f}, avg_accuracy_val: {avg_accuracy_val:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# MLP testing\n","avg_loss_test, avg_accuracy_test = classif.test_model(test_loader)\n","print(f\"avg_loss_test: {avg_loss_test:.4f}, avg_accuracy_test: {avg_accuracy_test:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Comparing with MLP trained on input images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classif_inputs = MLP(input_size, 16, 3, 10, lr_classif, loss, use_embeddings = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# MLP training\n","for epoch in range(epochs_classif):\n","    print(f\"epoch: {epoch + 1}/{epochs_classif}\")\n","    avg_loss_train, avg_accuracy_train = classif_inputs.train_model(train_loader)\n","\n","    # validation data\n","    avg_loss_val, avg_accuracy_val = classif_inputs.test_model(val_loader)\n","    \n","    print(f\"avg_loss_train: {avg_loss_train:.4f}, avg_accuracy_train: {avg_accuracy_train:.4f}\")\n","    print(f\"avg_loss_val: {avg_loss_val:.4f}, avg_accuracy_val: {avg_accuracy_val:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# MLP testing\n","avg_loss_test, avg_accuracy_test = classif_inputs.test_model(test_loader)\n","print(f\"avg_loss_test: {avg_loss_test:.4f}, avg_accuracy_test: {avg_accuracy_test:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Save a model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["route = \"models/x-x-24/\"\n","\n","# Create the directory if it does not exist\n","if not os.path.exists(route):\n","    os.makedirs(route)\n","\n","# Paths for the files\n","encoder_weights_path = os.path.join(route, \"encoder_weights.pth\")\n","decoder_weights_path = os.path.join(route, \"decoder_weights.pth\")\n","\n","# Save model weights\n","torch.save(model_encoder.state_dict(), encoder_weights_path)\n","torch.save(model_decoder.state_dict(), decoder_weights_path)\n","\n","hyperparameters = {\n","    \"learning_rate\": lr,\n","    \"batch_size\": batch_size,\n","    \"epochs\": epochs,\n","    \"latent_size\": latent_size,\n","    \"kernel_param_X\": kernel_param_X,\n","    \"kernel_param_Y\": kernel_param_Y,\n","    \"label_indep\": label_indep, \n","}\n","\n","# Convert the dictionary to a JSON string\n","hyp_json = json.dumps(hyperparameters)\n","\n","# Correct the file path and mode\n","hyperparameters_path = os.path.join(route, 'model_hyperparameters.txt')\n","with open(hyperparameters_path, 'w') as file:  # Changed mode to 'w'\n","    file.write(hyp_json)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Load a model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder_weights_path = \"GAE/models/Fashion_MNIST/7-5-24/encoder_weights.pth\"\n","decoder_weights_path = \"GAE/models/Fashion_MNIST/7-5-24/decoder_weights.pth\"\n","\n","model_encoder = GCNEncoder(input_size, latent_size)\n","model_decoder = GCNDecoder(latent_size, input_size)\n","model_encoder.load_state_dict(torch.load(encoder_weights_path))\n","model_decoder.load_state_dict(torch.load(decoder_weights_path))\n","\n","optimizer = Adam(list(model_encoder.parameters()) + list(model_decoder.parameters()), lr = lr)\n","criterion = nn.MSELoss()\n","model = GAE(model_encoder, model_decoder, kernel_param_X, optimizer, criterion, label_indep, kernel_param_Y)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
